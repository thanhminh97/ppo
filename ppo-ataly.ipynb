{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install \"gym [accept-rom-license, atari]\"","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"azsntCYCBWvp","outputId":"476b1e35-0cc2-4c2e-e32d-16f83ef16eb2","trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:34:55.608317Z","iopub.execute_input":"2025-05-03T13:34:55.608852Z","iopub.status.idle":"2025-05-03T13:35:13.648133Z","shell.execute_reply.started":"2025-05-03T13:34:55.608827Z","shell.execute_reply":"2025-05-03T13:35:13.647218Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.11/dist-packages (0.25.2)\nRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from gym[accept-rom-license,atari]) (1.26.4)\nRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym[accept-rom-license,atari]) (3.1.1)\nRequirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym[accept-rom-license,atari]) (0.0.8)\nINFO: pip is looking at multiple versions of gym[accept-rom-license,atari] to determine which version is compatible with other requirements. This could take a while.\nCollecting gym[accept-rom-license,atari]\n  Downloading gym-0.26.2.tar.gz (721 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nCollecting ale-py~=0.8.0 (from gym[accept-rom-license,atari])\n  Downloading ale_py-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\nCollecting autorom~=0.4.2 (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license,atari])\n  Downloading AutoROM-0.4.2-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from ale-py~=0.8.0->gym[accept-rom-license,atari]) (6.5.2)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license,atari]) (8.1.8)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license,atari]) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license,atari]) (4.67.1)\nCollecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license,atari])\n  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->gym[accept-rom-license,atari]) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->gym[accept-rom-license,atari]) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->gym[accept-rom-license,atari]) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->gym[accept-rom-license,atari]) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->gym[accept-rom-license,atari]) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->gym[accept-rom-license,atari]) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.18.0->gym[accept-rom-license,atari]) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.18.0->gym[accept-rom-license,atari]) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.18.0->gym[accept-rom-license,atari]) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.18.0->gym[accept-rom-license,atari]) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license,atari]) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license,atari]) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license,atari]) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license,atari]) (2025.1.31)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.18.0->gym[accept-rom-license,atari]) (2024.2.0)\nDownloading ale_py-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\nBuilding wheels for collected packages: gym, AutoROM.accept-rom-license\n  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827725 sha256=a52c7cd95fe53c9a89f5368e7ecbf4cd8face841f7331de9e5d87eb99fb742a1\n  Stored in directory: /root/.cache/pip/wheels/1c/77/9e/9af5470201a0b0543937933ee99ba884cd237d2faefe8f4d37\n  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for AutoROM.accept-rom-license: filename=autorom_accept_rom_license-0.6.1-py3-none-any.whl size=446709 sha256=365002b48bb150ed2ec7be2b3f32323b8d343da4ce1c37a3c8e10be989f9696f\n  Stored in directory: /root/.cache/pip/wheels/bc/fc/c6/8aa657c0d2089982f2dabd110efc68c61eb49831fdb7397351\nSuccessfully built gym AutoROM.accept-rom-license\nInstalling collected packages: AutoROM.accept-rom-license, autorom, gym, ale-py\n  Attempting uninstall: gym\n    Found existing installation: gym 0.25.2\n    Uninstalling gym-0.25.2:\n      Successfully uninstalled gym-0.25.2\n  Attempting uninstall: ale-py\n    Found existing installation: ale-py 0.10.1\n    Uninstalling ale-py-0.10.1:\n      Successfully uninstalled ale-py-0.10.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndopamine-rl 4.1.2 requires ale-py>=0.10.1, but you have ale-py 0.8.1 which is incompatible.\ndopamine-rl 4.1.2 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.8.1 autorom-0.4.2 gym-0.26.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"id":"qdp31bz7BWvq","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\ndef compute_gae(next_value, rewards, masks, values, gamma=0.999, tau=0.95):\n    gae = 0\n    returns = []\n    get_log_gae = []\n\n    # Duyệt ngược từ cuối episode về đầu episode\n    for i in reversed(range(len(rewards))):\n        # Tính toán delta\n        delta = rewards[i] + gamma * next_value * masks[i] - values[i]\n\n        # Cập nhật GAE\n        gae = delta + gamma * tau * masks[i] * gae\n\n        # Cập nhật next_value cho bước tiếp theo\n        next_value = values[i]\n\n        # Lưu giá trị returns và GAE\n        returns.append(gae + values[i])\n        get_log_gae.append(gae)\n\n    # Đảo ngược lại để trả về theo thứ tự thời gian gốc\n    returns = returns[::-1]\n    get_log_gae = get_log_gae[::-1]\n\n\n    return returns, get_log_gae","metadata":{"id":"pTuox8zUBWvq","trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:35:13.649534Z","iopub.execute_input":"2025-05-03T13:35:13.649895Z","iopub.status.idle":"2025-05-03T13:35:13.655389Z","shell.execute_reply.started":"2025-05-03T13:35:13.649873Z","shell.execute_reply":"2025-05-03T13:35:13.654729Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport torch as T\nimport torch.nn.functional as F\n\nimport numpy as np\nfrom torch.distributions.categorical import Categorical\nfrom torch.distributions.normal import Normal\n\ndef layer_init(layer, std=np.sqrt(2), bias_const=0.0):\n    torch.nn.init.orthogonal_(layer.weight, std)\n    torch.nn.init.constant_(layer.bias, bias_const)\n    return layer\n\nclass Agent(nn.Module):\n    def __init__(self, envs,device):\n        super(Agent, self).__init__()\n        self.network = nn.Sequential(\n            layer_init(nn.Conv2d(4, 32, 8, stride=4)),\n            nn.ReLU(),\n            layer_init(nn.Conv2d(32, 64, 4, stride=2)),\n            nn.ReLU(),\n            layer_init(nn.Conv2d(64, 64, 3, stride=1)),\n            nn.ReLU(),\n            nn.Flatten(),\n            layer_init(nn.Linear(64 * 7 * 7, 512)),\n            nn.ReLU(),\n        )\n        self.actor = layer_init(nn.Linear(512, envs.action_space.n), std=0.01)\n        self.critic = layer_init(nn.Linear(512, 1), std=1)\n        self.to(device)\n    def get_value(self, x):\n        return self.critic(self.network(x / 255.0))\n\n    def get_action_and_value(self, x, action=None):\n        hidden = self.network(x / 255.0)\n        logits = self.actor(hidden)\n        probs = Categorical(logits=logits)\n        if action is None:\n            action = probs.sample()\n        return action, probs.log_prob(action), probs.entropy(), self.critic(hidden)","metadata":{"id":"z_KzPtYXBWvq","trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:35:13.656194Z","iopub.execute_input":"2025-05-03T13:35:13.656427Z","iopub.status.idle":"2025-05-03T13:35:17.436405Z","shell.execute_reply.started":"2025-05-03T13:35:13.656405Z","shell.execute_reply":"2025-05-03T13:35:17.435647Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import torch\ndef ppo_loss(new_dist, actions, old_log_probs, advantages, clip_param):\n      new_log_probs = new_dist\n\n      ratio = (new_log_probs - old_log_probs).exp()\n\n      surr1 = ratio * advantages\n\n      surr2 = torch.clamp(ratio, 1.0 - clip_param, 1.0 + clip_param) * advantages\n\n      actor_loss = -torch.min(surr1, surr2)\n\n\n      return actor_loss.mean()","metadata":{"id":"wUguwQoqBWvr","trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:35:17.438032Z","iopub.execute_input":"2025-05-03T13:35:17.438310Z","iopub.status.idle":"2025-05-03T13:35:17.442648Z","shell.execute_reply.started":"2025-05-03T13:35:17.438293Z","shell.execute_reply":"2025-05-03T13:35:17.442070Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import torch\n\ndef clipped_critic_loss(new_value, old_value, returns, clip_param):\n      vf_loss1 = (new_value - returns).pow(2.)\n\n    # 2. MSE/L2 loss on the clipped value and the returns\n    # Here we create an \"approximation\" of the new value (aka the current value) by finding the difference\n    # between the \"new\" and \"old\" value and adding a clipped amount back to the old value\n      vpredclipped = old_value + torch.clamp(new_value - old_value, -clip_param, clip_param)\n    # Note that we ONLY backprop through the new value\n      vf_loss2 = (vpredclipped - returns).pow(2.)\n\n    # 3. Take the MAX between the two losses\n    # This trick has the effect of only updating the current value DIRECTLY if is it WORSE (higher error)\n    # than the old value.\n    # If the old value was worse then the \"approximation\" will be worse and we update\n    # the new value only a little bit!\n      critic_loss = torch.max(vf_loss1, vf_loss2)\n\n    # 4. Return the Expectation over the batch\n      return critic_loss.mean()","metadata":{"id":"WtkGB1uWBWvr","trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:35:17.443449Z","iopub.execute_input":"2025-05-03T13:35:17.444078Z","iopub.status.idle":"2025-05-03T13:35:17.488457Z","shell.execute_reply.started":"2025-05-03T13:35:17.444053Z","shell.execute_reply":"2025-05-03T13:35:17.487801Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def xuly_dulieu(env, model, gamma, tau, device):\n    obs, _ = env.reset()\n    dulieu = {\n        \"obs\": [],\n        \"action\": [],\n        \"reward\": [],\n        \"logprob\": [],\n        \"value\": [],\n        \"done\": []\n    }\n\n    for _ in range(512):\n        with torch.no_grad():\n            obs_array = np.array(obs)\n            obs_tensor = torch.tensor(obs_array, dtype=torch.float32).unsqueeze(0).to(device)\n            action, logprob, _, value = model.get_action_and_value(obs_tensor)\n\n        next_obs, reward, terminated, truncated, _ = env.step(action)\n        done = 0 if terminated or truncated else 1\n\n        dulieu[\"obs\"].append(obs_array)  # Save as np.array to avoid LazyFrames\n        dulieu[\"action\"].append(action)\n        dulieu[\"reward\"].append(reward)\n        dulieu[\"logprob\"].append(logprob.detach())\n        dulieu[\"value\"].append(value.detach())\n        dulieu[\"done\"].append(done)\n\n        obs = next_obs\n        if terminated or truncated:\n            obs, _ = env.reset()\n\n    with torch.no_grad():\n        next_value = model.get_value(\n            torch.tensor(np.array(obs), dtype=torch.float32).unsqueeze(0).to(device)\n        )\n\n    # GAE\n    returns, advantages = compute_gae(\n        next_value,\n        dulieu[\"reward\"],\n        dulieu[\"done\"],\n        dulieu[\"value\"],\n        gamma,\n        tau\n    )\n\n    advantages = torch.tensor(advantages, dtype=torch.float32).to(device)\n    advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\n    advantages = advantages.view(-1)\n    # Convert everything to tensors and shuffle\n    obs_tensor = torch.tensor(np.array(dulieu[\"obs\"]), dtype=torch.float32).to(device)\n    action_tensor = torch.cat(dulieu[\"action\"]).to(device)\n    logprob_tensor = torch.cat(dulieu[\"logprob\"]).to(device)\n    value_tensor = torch.cat(dulieu[\"value\"]).squeeze(-1).to(device)\n    return_tensor = torch.tensor(returns, dtype=torch.float32).to(device)\n\n    idx = torch.randperm(advantages.shape[0])\n    obs_tensor = obs_tensor[idx].reshape(4, 128, 4, 84, 84)\n    action_tensor = action_tensor[idx].reshape(4, 128)\n    logprob_tensor = logprob_tensor[idx].reshape(4, 128)\n    value_tensor = value_tensor[idx].reshape(4, 128)\n    return_tensor = return_tensor[idx].reshape(4, 128)\n    advantage_tensor = advantages[idx].reshape(4, 128)\n\n    rs = torch.tensor(dulieu[\"reward\"]).sum()\n\n    minibatch = {\n        \"obs\": obs_tensor,\n        \"action\": action_tensor,\n        \"logprob\": logprob_tensor,\n        \"value\": value_tensor,\n        \"returns\": return_tensor,\n        \"advantage\": advantage_tensor,\n    }\n\n    return minibatch, rs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:35:17.488979Z","iopub.execute_input":"2025-05-03T13:35:17.489160Z","iopub.status.idle":"2025-05-03T13:35:17.503480Z","shell.execute_reply.started":"2025-05-03T13:35:17.489145Z","shell.execute_reply":"2025-05-03T13:35:17.502865Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"\n\nimport torch\nimport numpy as np\nimport torch.nn as nn\n\ndef ppo_update(data_buffer, ppo_epochs, clip_param, model, optimizer,device):\n     for _ in range(ppo_epochs):\n        for i in range(len(data_buffer[\"obs\"])):\n\n            obs =data_buffer[\"obs\"][i].to(device)\n            logprob =data_buffer[\"logprob\"][i].to(device)\n            values = data_buffer[\"value\"][i].to(device)\n            returns = data_buffer[\"returns\"][i].to(device)\n            action = data_buffer[\"action\"][i]\n            # Clone advantage để tránh inplace operation\n            advantage = data_buffer[\"advantage\"][i].to(device)\n\n\n            _, n_logprob, entropy, n_value = model.get_action_and_value(obs, action)\n\n            # Tính toán loss của actor và critic\n            actor_loss = ppo_loss(n_logprob, action, logprob, advantage, clip_param)\n            critic_loss = clipped_critic_loss(n_value, values, returns, clip_param)\n\n            # Đảm bảo agent_loss là một scalar\n            agent_loss = actor_loss + 0.5 * critic_loss - 0.01 * entropy.mean()\n\n\n            # Debugging: Kiểm tra agent_loss có phải là scalar không\n           \n            optimizer.zero_grad()\n\n            # Backpropagation\n            agent_loss.backward()\n\n            # Cắt gradient norm để tránh cập nhật quá lớn\n            nn.utils.clip_grad_norm_(model.parameters(),0.5)\n\n            # Cập nhật optimizer\n            optimizer.step()\n    #print(actor_loss.item(),critic_loss.item())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:36:29.510288Z","iopub.execute_input":"2025-05-03T13:36:29.510854Z","iopub.status.idle":"2025-05-03T13:36:29.517377Z","shell.execute_reply.started":"2025-05-03T13:36:29.510830Z","shell.execute_reply":"2025-05-03T13:36:29.516536Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import gym\nimport torch\nimport numpy as np\nimport torch.optim as optim\nfrom stable_baselines3.common.atari_wrappers import (  # isort:skip\n    ClipRewardEnv,\n    EpisodicLifeEnv,\n    FireResetEnv,\n    MaxAndSkipEnv,\n    NoopResetEnv,\n)\nseed=42\nname=\"ALE/Breakout-v5\"\nenv = gym.make(name)\nenv = gym.wrappers.RecordEpisodeStatistics(env)\nenv = NoopResetEnv(env, noop_max=30)\nenv = MaxAndSkipEnv(env, skip=4)\nenv = EpisodicLifeEnv(env)\nenv = gym.wrappers.ResizeObservation(env, (84, 84))\nenv = gym.wrappers.GrayScaleObservation(env)\nenv = gym.wrappers.FrameStack(env, 4)\nenv.seed(seed)\nenv.action_space.seed(seed)\nenv.observation_space.seed(seed)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nlr = 2.5e-4\nppo_epochs = 4\nclip_param = 0.1\ngamma=0.99\ntau=0.95\nagent=Agent(env,device)\noptimizer = optim.Adam(agent.parameters(), lr=lr, eps=1e-5)\n\ndef tes(run_name,env):\n    observation,_ = env.reset()\n    obs = observation\n    k = 0\n    for _ in range(1000):\n        with torch.no_grad():\n            obs_s = torch.from_numpy(np.array(obs, dtype=np.float32))[None].to(device)\n\n            action, logprob, _, value = agent.get_action_and_value(obs_s)\n            action_s = action\n            # TRY NOT TO MODIFY: execute the game and log data.\n            next_obs, reward, terminated,ter , info = env.step(action_s)\n            k+=reward\n            obs=next_obs\n            # Fix for multi-env outputs\n            if terminated or ter :\n                break\n    return k\n\n\n\nfor i in range(1000):\n   du_lieu,rs= xuly_dulieu(env,agent,gamma, tau,device)\n   ppo_update(du_lieu, ppo_epochs, clip_param,agent,optimizer,device)\n   if i % 20 ==0:\n       print(i,rs.item())\n       k=tes(i,env)\n       print(k)\n       print()","metadata":{"id":"TGmaJOW-BWvr","trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:38:04.626199Z","iopub.execute_input":"2025-05-03T13:38:04.626864Z","iopub.status.idle":"2025-05-03T13:54:36.307197Z","shell.execute_reply.started":"2025-05-03T13:38:04.626841Z","shell.execute_reply":"2025-05-03T13:54:36.306225Z"}},"outputs":[{"name":"stdout","text":"0 18.0\n0.0\n\n20 22.0\n0.0\n\n40 31.0\n0.0\n\n60 39.0\n0.0\n\n80 46.0\n0.0\n\n100 43.0\n0.0\n\n120 39.0\n0.0\n\n140 54.0\n0.0\n\n160 36.0\n0.0\n\n180 40.0\n1.0\n\n200 43.0\n0.0\n\n220 40.0\n0.0\n\n240 44.0\n0.0\n\n260 52.0\n0.0\n\n280 44.0\n0.0\n\n300 54.0\n0.0\n\n320 42.0\n1.0\n\n340 47.0\n0.0\n\n360 42.0\n0.0\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/1230019760.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m    \u001b[0mdu_lieu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mxuly_dulieu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m    \u001b[0mppo_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdu_lieu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mppo_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_param\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/939949288.py\u001b[0m in \u001b[0;36mxuly_dulieu\u001b[0;34m(env, model, gamma, tau, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action_and_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mnext_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mterminated\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtruncated\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gym/wrappers/frame_stack.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mStacked\u001b[0m \u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minformation\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \"\"\"\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;34m\"\"\"Returns a modified observation using :meth:`self.observation` after calling :meth:`env.step`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;34m\"\"\"Returns a modified observation using :meth:`self.observation` after calling :meth:`env.step`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/atari_wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAtariStepReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwas_real_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mterminated\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# check current lives, make loss of life terminal,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/atari_wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mterminated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtruncated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_skip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mterminated\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_skip\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gymnasium/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    445\u001b[0m     ) -> tuple[WrapperObsType, SupportsFloat, bool, bool, dict[str, Any]]:\n\u001b[1;32m    446\u001b[0m         \u001b[0;34m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m     def reset(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gym/wrappers/record_episode_statistics.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mtruncateds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0minfos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         ) = self.env.step(action)\n\u001b[0m\u001b[1;32m    112\u001b[0m         assert isinstance(\n\u001b[1;32m    113\u001b[0m             \u001b[0minfos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gym/wrappers/order_enforcing.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mResetNeeded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot call env.step() before calling env.reset()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gym/wrappers/env_checker.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0menv_step_passive_checker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ale_py/env/gym.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action_ind)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeskip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0mreward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0male\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m         \u001b[0mis_terminal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0male\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame_over\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_truncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mis_truncated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0male\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame_truncated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":11},{"cell_type":"code","source":"from typing import Tuple, Dict, Optional, Iterable, Callable\n\nimport numpy as np\nimport seaborn as sns\n\nimport matplotlib\nfrom matplotlib import animation\n\nfrom IPython.display import HTML\n\nimport gym\nfrom gym import spaces\nfrom gym.error import DependencyNotInstalled\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"id":"VrlGqInV1t74","trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:54:48.095090Z","iopub.execute_input":"2025-05-03T13:54:48.095360Z","iopub.status.idle":"2025-05-03T13:54:49.553667Z","shell.execute_reply.started":"2025-05-03T13:54:48.095339Z","shell.execute_reply":"2025-05-03T13:54:49.553124Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def display_video(frames):\n    # Copied from: https://colab.research.google.com/github/deepmind/dm_control/blob/master/tutorial.ipynb\n    orig_backend = matplotlib.get_backend()\n    matplotlib.use('Agg')\n    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n    matplotlib.use(orig_backend)\n    ax.set_axis_off()\n    ax.set_aspect('equal')\n    ax.set_position([0, 0, 1, 1])\n    im = ax.imshow(frames[0])\n    def update(frame):\n        im.set_data(frame)\n        return [im]\n    anim = animation.FuncAnimation(fig=fig, func=update, frames=frames,\n                                    interval=50, blit=True, repeat=False)\n    return HTML(anim.to_html5_video())","metadata":{"id":"ziVuphul1vRO","trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:54:59.713634Z","iopub.execute_input":"2025-05-03T13:54:59.714408Z","iopub.status.idle":"2025-05-03T13:54:59.719505Z","shell.execute_reply.started":"2025-05-03T13:54:59.714386Z","shell.execute_reply":"2025-05-03T13:54:59.718763Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"env = gym.make(\"ALE/Breakout\",render_mode='rgb_array')\nseed=42\n\nenv = gym.wrappers.RecordEpisodeStatistics(env)\nenv = NoopResetEnv(env, noop_max=30)\nenv = MaxAndSkipEnv(env, skip=4)\nenv = EpisodicLifeEnv(env)\nenv = gym.wrappers.ResizeObservation(env, (84, 84))\nenv = gym.wrappers.GrayScaleObservation(env)\nenv = gym.wrappers.FrameStack(env, 4)\nenv.seed(seed)\nenv.action_space.seed(seed)\nenv.observation_space.seed(seed)","metadata":{"id":"0r7_aaqfBWvs","trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:55:18.189449Z","iopub.execute_input":"2025-05-03T13:55:18.189742Z","iopub.status.idle":"2025-05-03T13:55:18.515208Z","shell.execute_reply.started":"2025-05-03T13:55:18.189720Z","shell.execute_reply":"2025-05-03T13:55:18.514635Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/gym/envs/registration.py:563: UserWarning: \u001b[33mWARN: Using the latest versioned environment `ALE/Breakout-v5` instead of the unversioned environment `ALE/Breakout`.\u001b[0m\n  logger.warn(\n/usr/local/lib/python3.11/dist-packages/gymnasium/core.py:297: UserWarning: \u001b[33mWARN: env.seed to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.seed` for environment variables or `env.get_attr('seed')` that will search the reminding wrappers.\u001b[0m\n  logger.warn(\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"[42]"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"obs,_ = env.reset()\ndone = False\nk=0\nframes = []\nfor i in range(1000):\n    with torch.no_grad():\n      obs_np = np.array(obs)  \n      \n      obs_s= torch.tensor([obs_np], dtype=torch.float32).to(device)\n\n      action, logprob, _, value = agent.get_action_and_value(obs_s)\n    next_obs, reward, done,ter, info = env.step(action)\n    obs=next_obs\n    img = env.render()\n    frames.append(img)\n    if done or ter:\n        break\n    k += reward","metadata":{"id":"C_CmDkvf1vZe","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8befcb4d-a065-425d-e564-b61a0a1764a3","trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:55:53.451711Z","iopub.execute_input":"2025-05-03T13:55:53.452489Z","iopub.status.idle":"2025-05-03T13:55:53.998145Z","shell.execute_reply.started":"2025-05-03T13:55:53.452458Z","shell.execute_reply":"2025-05-03T13:55:53.997334Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"action","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:35:42.912620Z","iopub.status.idle":"2025-05-03T13:35:42.912926Z","shell.execute_reply.started":"2025-05-03T13:35:42.912761Z","shell.execute_reply":"2025-05-03T13:35:42.912776Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(obs_s[0][0][0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:35:42.914193Z","iopub.status.idle":"2025-05-03T13:35:42.914467Z","shell.execute_reply.started":"2025-05-03T13:35:42.914339Z","shell.execute_reply":"2025-05-03T13:35:42.914349Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"obs_s[0][0][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:35:42.915287Z","iopub.status.idle":"2025-05-03T13:35:42.915488Z","shell.execute_reply.started":"2025-05-03T13:35:42.915393Z","shell.execute_reply":"2025-05-03T13:35:42.915401Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"display_video(frames)","metadata":{"id":"Fr3uGAcc2gIn","colab":{"base_uri":"https://localhost:8080/","height":541},"outputId":"2c2a533e-1cf7-4540-b523-da418f059a22","trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:55:56.595944Z","iopub.execute_input":"2025-05-03T13:55:56.596212Z","iopub.status.idle":"2025-05-03T13:55:58.934697Z","shell.execute_reply.started":"2025-05-03T13:55:56.596191Z","shell.execute_reply":"2025-05-03T13:55:58.933992Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<video width=\"500\" height=\"500\" controls autoplay>\n  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAIGZ0eXBNNFYgAAACAE00ViBpc29taXNvMmF2YzEAAAAIZnJlZQAAKAFtZGF0AAACrgYF//+q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\nMDA=\n\">\n  Your browser does not support the video tag.\n</video>"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"","metadata":{"id":"tiwSc8I-2hbv","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"matrix3=dataset[\"train\"]['actions']","metadata":{"id":"IH09XPLpvy0I","trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:35:42.917821Z","iopub.status.idle":"2025-05-03T13:35:42.918063Z","shell.execute_reply.started":"2025-05-03T13:35:42.917938Z","shell.execute_reply":"2025-05-03T13:35:42.917949Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"matrix3[757][0]","metadata":{"id":"uBvMJeMGv3jA","trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:35:42.919653Z","iopub.status.idle":"2025-05-03T13:35:42.919894Z","shell.execute_reply.started":"2025-05-03T13:35:42.919794Z","shell.execute_reply":"2025-05-03T13:35:42.919804Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"env.reset()\nframes = []\ntong_phan_thuong=0\nfor i in range(len(matrix3[757])) :\n    frames.append(env.render(mode=\"rgb_array\"))\n    action = matrix3[150][i].detach().cpu().numpy()\n    state, reward, done, _ = env.step(action)\n    tong_phan_thuong+=reward\nprint(tong_phan_thuong)","metadata":{"id":"NWUY6NMrvy3T","trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:35:42.920647Z","iopub.status.idle":"2025-05-03T13:35:42.920864Z","shell.execute_reply.started":"2025-05-03T13:35:42.920764Z","shell.execute_reply":"2025-05-03T13:35:42.920773Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"display_video(frames)","metadata":{"id":"96VKOedHrj-t","trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:35:42.921949Z","iopub.status.idle":"2025-05-03T13:35:42.922249Z","shell.execute_reply.started":"2025-05-03T13:35:42.922110Z","shell.execute_reply":"2025-05-03T13:35:42.922124Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"9DDIHCdck66b","trusted":true},"outputs":[],"execution_count":null}]}